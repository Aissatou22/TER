{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-1-f9defd872c24>, line 344)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-f9defd872c24>\"\u001b[0;36m, line \u001b[0;32m344\u001b[0m\n\u001b[0;31m    ————————————————\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "# Author:Zhou Yang\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import os.path\n",
    "import re\n",
    "\n",
    "agreement = 'https://'\n",
    "language = 'en'\n",
    "organization = '.wikipedia.org/w/api.php'\n",
    "\n",
    "API_URL = agreement + language + organization\n",
    "\n",
    "\n",
    "program = os.path.basename(sys.argv[0])\n",
    "logger = logging.getLogger(program)\n",
    "logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s')\n",
    "\n",
    "\n",
    "def pageid(title = None, np = 0):\n",
    "    global API_URL\n",
    "    URL = API_URL\n",
    "    query_params = {\n",
    "        'action': 'query',\n",
    "        'prop': 'info',\n",
    "        'format': 'json',\n",
    "        'titles': title\n",
    "    }\n",
    "    if np != 0:\n",
    "        query_params['titles'] = 'Category:' + title\n",
    "    try:\n",
    "        r = requests.get(URL, params=query_params)\n",
    "        r.raise_for_status()\n",
    "        html, r.encoding = r.text, 'gb2312'\n",
    "    except:\n",
    "        html = \"\"\n",
    "    if html == \"\":\n",
    "        return -1\n",
    "    else:\n",
    "        try:\n",
    "            text = json.loads(html, encoding='gb2312')\n",
    "        except json.JSONDecodeError:\n",
    "            return -1\n",
    "        try:\n",
    "            for i in text[\"query\"]['pages']:\n",
    "                return int(i)\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "def summary(title = None):\n",
    "    global API_URL\n",
    "    URL = API_URL\n",
    "    query_params = {\n",
    "        'action': 'query',\n",
    "        'prop': 'extracts',\n",
    "        'explaintext': '',\n",
    "        'exintro': '',\n",
    "        'format': 'json',\n",
    "        'titles': title\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(URL, params=query_params)\n",
    "        r.raise_for_status()\n",
    "        html, r.encoding = r.text, 'gb2312'\n",
    "    except:\n",
    "        logger.error('error summary about ' + title)\n",
    "        return \"\"\n",
    "    text = json.loads(html, encoding='gb2312')\n",
    "    id = list(text[\"query\"][\"pages\"].keys())[0]\n",
    "    try:\n",
    "        return text[\"query\"][\"pages\"][id][\"extract\"]\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def body(title = None):\n",
    "    global API_URL\n",
    "    URL = API_URL\n",
    "    query_params = {\n",
    "        'action': 'query',\n",
    "        'prop': 'extracts',\n",
    "        'exlimit' : 'max',\n",
    "        'format': 'json',\n",
    "        'titles': title\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(URL, params=query_params)\n",
    "        r.raise_for_status()\n",
    "        html, r.encoding = r.text, 'gb2312'\n",
    "    except:\n",
    "        logger.error('error body about ' + title)\n",
    "        return \"\"\n",
    "    text = json.loads(html, encoding='gb2312')\n",
    "    id = list(text[\"query\"][\"pages\"].keys())[0]\n",
    "    try:\n",
    "        html_text = text[\"query\"][\"pages\"][id][\"extract\"]\n",
    "        def stripTagSimple(htmlStr):\n",
    "            '''\n",
    "            最简单的过滤html <>标签的方法    注意必须是<任意字符>  而不能单纯是<>\n",
    "            :param htmlStr:\n",
    "            '''\n",
    "            #         dr =re.compile(r'<[^>]+>',re.S)\n",
    "            dr = re.compile(r'</?\\w+[^>]*>', re.S)\n",
    "            htmlStr = re.sub(dr, '', htmlStr)\n",
    "            return htmlStr\n",
    "        html_text = stripTagSimple(html_text)\n",
    "        html_text = str(html_text).replace(\"\\n\", \"\")\n",
    "        return html_text\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def links(title = None):\n",
    "    global API_URL\n",
    "    URL = API_URL\n",
    "    query_params = {\n",
    "        'action': 'query',\n",
    "        'prop': 'links',\n",
    "        'pllimit': 'max',\n",
    "        'plnamespace': '0',\n",
    "        'format': 'json',\n",
    "        'titles': title\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(URL, params=query_params)\n",
    "        r.raise_for_status()\n",
    "        html, r.encoding = r.text, 'gb2312'\n",
    "    except:\n",
    "        logger.error('error links about ' + title)\n",
    "        return list()\n",
    "    text = json.loads(html, encoding='gb2312')\n",
    "    id = list(text[\"query\"][\"pages\"].keys())[0]\n",
    "    link = list()\n",
    "    summ = summary(title)\n",
    "    try:\n",
    "        for obj in text[\"query\"]['pages'][id][\"links\"]:\n",
    "            if obj['title'] in summ or obj['title'].lower() in summ:\n",
    "                link.append(obj['title'])\n",
    "    except:\n",
    "        return link\n",
    "    return link\n",
    "\n",
    "def linkss(title = None):\n",
    "    global API_URL\n",
    "    URL = API_URL\n",
    "    query_params = {\n",
    "        'action': 'query',\n",
    "        'prop': 'links',\n",
    "        'pllimit': 'max',\n",
    "        'plnamespace': '0',\n",
    "        'format': 'json',\n",
    "        'titles': title\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(URL, params=query_params)\n",
    "        r.raise_for_status()\n",
    "        html, r.encoding = r.text, 'gb2312'\n",
    "    except:\n",
    "        logger.error('error linkss about ' + title)\n",
    "        return list()\n",
    "    text = json.loads(html, encoding='gb2312')\n",
    "    id = list(text[\"query\"][\"pages\"].keys())[0]\n",
    "    link = list()\n",
    "    try:\n",
    "        for obj in text[\"query\"]['pages'][id][\"links\"]:\n",
    "            link.append(obj['title'])\n",
    "    except:\n",
    "        return link\n",
    "    return link\n",
    "\n",
    "def backlinks(title = None):\n",
    "    global API_URL\n",
    "    URL = API_URL\n",
    "    query_params = {\n",
    "        'action': 'query',\n",
    "        'list': 'backlinks',\n",
    "        'bllimit': 'max',\n",
    "        'blnamespace': '0',\n",
    "        'format': 'json',\n",
    "        'bltitle': title\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(URL, params=query_params)\n",
    "        r.raise_for_status()\n",
    "        html, r.encoding = r.text, 'gb2312'\n",
    "    except:\n",
    "        logger.error('error backlinks about ' + title)\n",
    "        return list()\n",
    "    text = json.loads(html, encoding='gb2312')\n",
    "    link = list()\n",
    "    try:\n",
    "        link = [obj['title'] for obj in text[\"query\"][\"backlinks\"]]\n",
    "    except:\n",
    "        return link\n",
    "    return link\n",
    "\n",
    "def categories(title = None):\n",
    "    global API_URL\n",
    "    URL = API_URL\n",
    "    query_params = {\n",
    "        'action': 'query',\n",
    "        'prop': 'categories',\n",
    "        'cllimit': 'max',\n",
    "        'clshow': '!hidden',\n",
    "        'format': 'json',\n",
    "        'clcategories': '',\n",
    "        'titles': title\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(URL, params=query_params)\n",
    "        r.raise_for_status()\n",
    "        html, r.encoding = r.text, 'gb2312'\n",
    "    except:\n",
    "        logger.error('error categories about ' + title)\n",
    "        return list()\n",
    "    text = json.loads(html, encoding='gb2312')\n",
    "    id = list(text[\"query\"][\"pages\"].keys())[0]\n",
    "    category = set()\n",
    "    if id != -1:\n",
    "        try:\n",
    "            category = [obj['title'][9:] for obj in text[\"query\"]['pages'][id][\"categories\"]]\n",
    "        except:\n",
    "            return category\n",
    "    return category\n",
    "\n",
    "def redirects(title=None):\n",
    "    global API_URL\n",
    "    URL = API_URL\n",
    "    query_params = {\n",
    "        'action': 'query',\n",
    "        'prop': 'redirects',\n",
    "        'rdlimit': 'max',\n",
    "        'format': 'json',\n",
    "        'titles': title\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(URL, params=query_params)\n",
    "        r.raise_for_status()\n",
    "        html, r.encoding = r.text, 'gb2312'\n",
    "    except:\n",
    "        logger.error('error redirects about ' + title)\n",
    "        return list()\n",
    "    text = json.loads(html, encoding='gb2312')\n",
    "    id = list(text[\"query\"][\"pages\"].keys())[0]\n",
    "    redirect = list()\n",
    "    if id != -1:\n",
    "        try:\n",
    "            redirect = [obj['title'] for obj in text[\"query\"]['pages'][id][\"redirects\"]]\n",
    "        except:\n",
    "            return redirect\n",
    "    return redirect\n",
    "\n",
    "def subcats(title=None):\n",
    "    global API_URL\n",
    "    URL = API_URL\n",
    "    query_params = {\n",
    "        'action': 'query',\n",
    "        'list': 'categorymembers',\n",
    "        'cmtype': 'subcat',\n",
    "        'cmlimit': 'max',\n",
    "        'format': 'json',\n",
    "        'cmtitle': 'Category:' + title\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(URL, params=query_params)\n",
    "        r.raise_for_status()\n",
    "        html, r.encoding = r.text, 'gb2312'\n",
    "    except:\n",
    "        logger.error('error subcats about ' + title)\n",
    "        return list()\n",
    "    text = json.loads(html, encoding='gb2312')\n",
    "    subcat = list()\n",
    "    try:\n",
    "        subcat = [obj['title'][9:] for obj in text[\"query\"]['categorymembers']]\n",
    "    except:\n",
    "        return subcat\n",
    "    return subcat\n",
    "\n",
    "def supercats(title=None):\n",
    "    global API_URL\n",
    "    URL = API_URL\n",
    "    query_params = {\n",
    "        'action': 'query',\n",
    "        'prop': 'categories',\n",
    "        'cllimit': 'max',\n",
    "        'format': 'json',\n",
    "        'clshow': '!hidden',\n",
    "        'titles': 'Category:' + title\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(URL, params=query_params)\n",
    "        r.raise_for_status()\n",
    "        html, r.encoding = r.text, 'gb2312'\n",
    "    except:\n",
    "        logger.error('error supercats about ' + title)\n",
    "        return list()\n",
    "    text = json.loads(html, encoding='gb2312')\n",
    "    id = list(text[\"query\"][\"pages\"].keys())[0]\n",
    "    supercat = list()\n",
    "    if id != -1:\n",
    "        try:\n",
    "            supercat = [obj['title'][9:] for obj in text[\"query\"]['pages'][id][\"categories\"]]\n",
    "        except:\n",
    "            return supercat\n",
    "    return supercat\n",
    "\n",
    "def contributors(title=None):\n",
    "    global API_URL\n",
    "    URL = API_URL\n",
    "    query_params = {\n",
    "        'action': 'query',\n",
    "        'prop': 'contributors',\n",
    "        'pclimit': 'max',\n",
    "        'format': 'json',\n",
    "        'titles': title\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(URL, params=query_params)\n",
    "        r.raise_for_status()\n",
    "        html, r.encoding = r.text, 'gb2312'\n",
    "    except:\n",
    "        logger.error('error linkss about ' + title)\n",
    "        return list()\n",
    "    text = json.loads(html, encoding='gb2312')\n",
    "    id = list(text[\"query\"][\"pages\"].keys())[0]\n",
    "    contributors = list()\n",
    "    try:\n",
    "        for obj in text[\"query\"]['pages'][id][\"contributors\"]:\n",
    "            contributors.append(obj['userid'])\n",
    "    except:\n",
    "        return contributors\n",
    "    return contributors\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    title = \"Computer networks\"\n",
    "    id = pageid(title, np = 4)\n",
    "    summ = summary(title)\n",
    "    Out = links(title)\n",
    "    print(id)\n",
    "    print(summ)\n",
    "    print(Out)\n",
    "————————————————\n",
    "版权声明：本文为CSDN博主「领头“洋”」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。\n",
    "原文链接：https://blog.csdn.net/qq_43549752/article/details/88894616"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(terEnv)",
   "language": "python",
   "name": "terenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
